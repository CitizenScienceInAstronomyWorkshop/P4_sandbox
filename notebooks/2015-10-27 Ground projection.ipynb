{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from pysis.util import file_variations\n",
    "import os\n",
    "from pysis import CubeFile\n",
    "from pysis.isis import cubenorm, handmos, hi2isis, hical, histitch, spiceinit, getkey\n",
    "import subprocess as sp\n",
    "from pysis.exceptions import ProcessError\n",
    "import sys\n",
    "\n",
    "# case 2: turn IMG to cub, give information of it (spiceinit), don't calibrate it\n",
    "def nocal_hi(img_name):\n",
    "    (img_name, cub_name) = file_variations(img_name, ['.IMG', '.cub'])\n",
    "    # something wrong here, if just put one extension in it, the name will contain brankets\n",
    "    try:\n",
    "        hi2isis(from_=img_name, to=cub_name)\n",
    "        spiceinit(from_=cub_name)\n",
    "    except ProcessError as e:\n",
    "        print(e.stdout)\n",
    "        print(e.stderr)\n",
    "        sys.exit()\n",
    "\n",
    "# stitch _0 and _1 together and normalize it\n",
    "def stit_norm_hi(img1, img2):\n",
    "    cub = img1[0:20]+'.cub'\n",
    "    (cub, norm) = file_variations(cub, ['.cub', '.norm.cub'])   # same here\n",
    "    try:\n",
    "        histitch(from1=img1, from2=img2, to=cub)\n",
    "        cubenorm(from_=cub, to=norm)\n",
    "    except ProcessError as e:\n",
    "        print(e.stdout)\n",
    "        print(e.stderr)\n",
    "        sys.exit()\n",
    "        \n",
    "def hi2mos(nm):\n",
    "    os.chdir('/Users/klay6683/data/planet4/season2_3_EDRs')\n",
    "    print('Processing the EDR data associated with '+nm)\n",
    "\n",
    "    mos_name = 'redMosaic'+nm+'.cub'\n",
    "#     status = os.path.isfile(mos_name)\n",
    "    status = False\n",
    "    if status is True:\n",
    "        print('skip processing '+nm+'...')\n",
    "        return nm, False\n",
    "    else:\n",
    "        nm = nm+'_RED'\n",
    "        channel = [4, 5]\n",
    "        ccd = [0, 1]\n",
    "\n",
    "        for c in channel:\n",
    "            for chip in ccd:\n",
    "                nocal_hi(nm+str(c)+'_'+str(chip)+'.IMG')\n",
    "\n",
    "            stit_norm_hi(nm+str(c)+'_0.cub', nm+str(c)+'_1.cub')\n",
    "\n",
    "        # handmos part\n",
    "        im0 = CubeFile.open(nm+'4.norm.cub')  # use CubeFile to get lines and samples\n",
    "        # use linux commands to get binning mode\n",
    "        bin = int(getkey(from_=nm+'4.norm.cub', objname=\"isiscube\", grpname=\"instrument\",\n",
    "                  keyword=\"summing\"))\n",
    "\n",
    "        # because there is a gap btw RED4 & 5, nsamples need to first make space\n",
    "        # for 2 cubs then cut some overlap pixels\n",
    "        try:\n",
    "            handmos(from_=nm+'4.norm.cub', mosaic=mos_name, nbands=1, outline=1, outband=1,\n",
    "                    create='Y', outsample=1, nsamples=im0.samples*2-48//bin, \n",
    "                    nlines=im0.lines)\n",
    "        except ProcessError as e:\n",
    "            print(\"STDOUT:\", e.stdout)\n",
    "            print(\"STDERR:\", e.stderr)\n",
    "        im0 = CubeFile.open(nm+'5.norm.cub')  # use CubeFile to get lines and samples\n",
    "\n",
    "        # deal with the overlap gap between RED4 & 5:\n",
    "        handmos(from_=nm+'5.norm.cub', mosaic=mos_name, outline=1, outband=1, create='N',\n",
    "                outsample=im0.samples-48//bin+1)  \n",
    "        return nm, True    \n",
    "\n",
    "\n",
    "def cleanup(data_dir, img):\n",
    "    # do some cleanup removing temporary files\n",
    "    # removing ISIS cubes made during processing that aren't needed\n",
    "    fs = glob.glob(data_dir+'/'+img+'_RED*.cub')\n",
    "\n",
    "    print(fs)\n",
    "    for f in fs:\n",
    "        os.remove(f)\n",
    "\n",
    "    # removing the normalized files\n",
    "\n",
    "    fs = glob.glob(data_dir+'/'+img+'_RED*.norm.cub')\n",
    "    for f in fs:\n",
    "        os.remove(f)\n",
    "\n",
    "    # remove the raw EDR data\n",
    "\n",
    "    fs = glob.glob(data_dir+'/'+img+'_RED*.IMG')\n",
    "    for f in fs:\n",
    "        os.remove(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_names = pd.read_table('/Users/klay6683/Dropbox/data/planet4/season2_3_image_names.txt',\n",
    "                          header=None, squeeze=True)\n",
    "img_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd ~/data/planet4/season2_3_EDRs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ipyparallel import Client\n",
    "c = Client()\n",
    "\n",
    "lbview = c.load_balanced_view()\n",
    "dview = c.direct_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px \n",
    "from __future__ import print_function,division\n",
    "from pysis.util import file_variations\n",
    "import os\n",
    "from pysis import CubeFile\n",
    "from pysis.isis import cubenorm, handmos, hi2isis, hical, histitch, spiceinit, getkey\n",
    "import subprocess as sp\n",
    "from pysis.exceptions import ProcessError\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dview.push({'nocal_hi':nocal_hi,\n",
    "            'stit_norm_hi':stit_norm_hi})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = lbview.map_async(hi2mos, img_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from iuvs.multitools import nb_progress_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_progress_display(results, img_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for res in results:\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rm -f *RED*.cub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xy2latlon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pysis.isis import campt\n",
    "from pysis.exceptions import ProcessError\n",
    "import pvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "edrpath = Path('/Users/klay6683/data/planet4/season2_3_EDRs/')\n",
    "clusterpath = Path('/Users/klay6683/Dropbox/data/planet4/inca_s23_0.5cut_applied/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obsids = !cat /Users/klay6683/Dropbox/data/planet4/season2_3_image_names.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fpaths = [item for obsid in obsids for item in (clusterpath.glob(\"{}_*.hdf\".format(obsid)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blotch_coords = ['', 'p1', 'p2', 'p3', 'p4']\n",
    "fan_coords = ['', 'arm1', 'arm2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ipyparallel import Client\n",
    "c = Client()\n",
    "\n",
    "lbview = c.load_balanced_view()\n",
    "dview = c.direct_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with dview.sync_imports():\n",
    "    from pysis.isis import campt\n",
    "    from pysis.exceptions import ProcessError\n",
    "    from pathlib import Path\n",
    "    from ipyparallel import CompositeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def do_campt(mosaicname, savepath, temppath):\n",
    "    try:\n",
    "        campt(from_=mosaicname, to=savepath, format='flat', append='no',\n",
    "              coordlist=temppath, coordtype='image')\n",
    "    except ProcessError as e:\n",
    "        print(e.stderr)\n",
    "        return obsid, False\n",
    "\n",
    "\n",
    "def process_inpath(inpath, marking, mosaicpath):\n",
    "    coords_switch = dict(blotches=blotch_coords,\n",
    "                         fans=fan_coords)\n",
    "    \n",
    "    df = pd.read_hdf(str(inpath), 'df')\n",
    "    for coord in coords_switch[marking]:\n",
    "        print(\"Coord\", coord)\n",
    "        if coord == '':\n",
    "            name = 'base'\n",
    "            tempcoords = ['x', 'y']\n",
    "        else:\n",
    "            name = coord\n",
    "            tempcoords = [coord + '_x', coord + '_y']\n",
    "        print(\"Tempcoords\", tempcoords)\n",
    "        temppath = inpath.with_suffix('.tocampt')\n",
    "        try:\n",
    "            df[tempcoords].to_csv(str(temppath), header=False, index=False)\n",
    "        except KeyError:\n",
    "            return False\n",
    "        print(\"name\", name)\n",
    "        savename = \"{stem}_{c}_campt_out.csv\".format(stem=inpath.stem, c=name)\n",
    "        print(\"savename\", savename)\n",
    "        savepath = clusterpath / savename\n",
    "        try:\n",
    "            do_campt(mosaicpath, savepath, temppath)\n",
    "        except:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def xy2latlon(inpath):\n",
    "    d = dict(inpath=inpath)\n",
    "    edrpath = Path('/Users/klay6683/data/planet4/season2_3_EDRs/')\n",
    "    tokens = inpath.stem.split('_')\n",
    "    obsid = '_'.join(tokens[:3])\n",
    "    marking = tokens[-1]\n",
    "    mosaicname = 'redMosaic' + obsid + '.cub'\n",
    "    mosaicpath = edrpath / mosaicname\n",
    "    ok = process_inpath(inpath, marking, mosaicpath)\n",
    "    d['ok'] = ok\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dview.push(dict(process_inpath=process_inpath,\n",
    "                do_campt=do_campt,\n",
    "                blotch_coords=blotch_coords,\n",
    "                fan_coords=fan_coords,\n",
    "                clusterpath=Path('/Users/klay6683/Dropbox/data/planet4/'\n",
    "                                 'inca_s23_0.5cut_applied/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xy2latlon(fpaths[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = lbview.map_async(xy2latlon, fpaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from iuvs.multitools import nb_progress_display\n",
    "\n",
    "nb_progress_display(results, fpaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = pd.DataFrame(results.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res.ok.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res[res.ok==False].inpath.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining campt results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p = fpaths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GroundMarking(object):\n",
    "    def __init__(self, resultfile):\n",
    "        self.p = Path(resultfile)\n",
    "        \n",
    "        # this loop creates filename paths for all coords campt output files\n",
    "        # and assigns them to object attributes, like\n",
    "        # self.basefile, self.p1file, etc.\n",
    "        self.paths = []\n",
    "        self.mapped_coords = []\n",
    "        for coord in self.coords:\n",
    "            path = self.campt_fname(coord)\n",
    "            setattr(self, coord+'file', path)\n",
    "            self.paths.append(path)\n",
    "            self.store_mapped_coords(coord, path)\n",
    "        self.mapped_coords = pd.concat(self.mapped_coords, axis=1)\n",
    "        newpath = self.p.with_name(self.p.stem+'_latlons.csv')\n",
    "        self.mapped_coords.to_csv(str(newpath), index=False)\n",
    "        self.coordspath = newpath\n",
    "\n",
    "    def campt_fname(self, coordname):\n",
    "        return self.p.with_name(self.p.stem + '_{}_campt_out.csv'.format(coordname))\n",
    "    \n",
    "    def store_mapped_coords(self, coord, path):\n",
    "        df = pd.read_csv(path)\n",
    "        subdf = df[['PlanetographicLatitude',\n",
    "                    'PositiveEast360Longitude']]\n",
    "        subdf.columns = [coord+'_lat', coord+'_lon']\n",
    "        self.mapped_coords.append(subdf)\n",
    "\n",
    "class GroundBlotch(GroundMarking):\n",
    "    coords = ['base', 'p1', 'p2', 'p3', 'p4']\n",
    "    kind = 'blotch'\n",
    "\n",
    "\n",
    "class GroundFan(GroundMarking):\n",
    "    coords = ['base', 'arm1', 'arm2']\n",
    "    kind = 'fan'\n",
    "\n",
    "    \n",
    "def get_ground_marking(fname):\n",
    "    tokens = Path(fname).stem.split('_')\n",
    "    if tokens[-1] == 'blotches':\n",
    "        return GroundBlotch(fname)\n",
    "    else:\n",
    "        return GroundFan(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for path in fpaths:\n",
    "    print(path.stem)\n",
    "    get_ground_marking(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}